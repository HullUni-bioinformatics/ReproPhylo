{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "EMBL/Benbank Parser\n",
      "===================\n",
      "\n",
      "This is a script that will extract records from gb or embl files and will organise them in a database and fasta files based on a guide file written by the user. Most of the script is made of subroutines so that the actual script will be short and clear, eg.:\n",
      "\n",
      "<pre>\n",
      "import some_module as sm                                                   #(nice. may keep it)\n",
      "\n",
      "data_folder = './data/'\n",
      "\n",
      "input_filenames_list = (data_folder + 'primates.gb', data_folder + 'primates1.gb')\n",
      "\n",
      "generators = sm.read_embl_genbank(input_filenames_list)                    #make one generator per gb file\n",
      "\n",
      "datasets_to_get = sm.build_data_dict('example_guide_table.txt')            #make empty dict\n",
      "\n",
      "datasets_to_get = sm.iter_generators(generators, datasets_to_get)          #add sequence records\n",
      "\n",
      "datasets_to_get = write_fasta_file_from(datasets_to_get, path=data_folder) #print fasta files and\n",
      "                                                                           #add path to fasta to dict\n",
      "\n",
      "check_datasets(datasets_to_get)                                            #look for missing data points\n",
      "\n",
      "</pre>\n",
      "\n",
      "**The output for this will be:**  \n",
      "<pre>\n",
      "Datatype  dna\n",
      "CDS\tcox1,COX1,coi,COI,CoI\n",
      "OK\n",
      "CDS\tnd5,ND5,nadh5,NADH5\n",
      "OK\n",
      "rRNA\t18s,18S,SSU,18S ribosomal RNA\n",
      "OK\n",
      "\n",
      "Accepted: /media/amir/DATA/work/Dropbox/ReproPhylo/data/primates.gb\n",
      "Accepted: /media/amir/DATA/work/Dropbox/ReproPhylo/data/primates1.gb\n",
      "\n",
      "Macaca mulatta missing from:\n",
      "dataset0_cox1.fasta\n",
      "dataset1_nd5.fasta\n",
      "Macaca mulatta lasiotus missing from:\n",
      "dataset2_18s.fasta\n",
      "\n",
      "</pre>\n",
      "\n",
      "**In addition to three fasta files**  \n",
      "<pre>\n",
      "./data/dataset0_cox1.fasta\n",
      "./data/dataset1_nd5.fasta\n",
      "./data/dataset2_18s.fasta\n",
      "</pre>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write example guide file\n",
      "------------------------\n",
      "Defines which genes to get from the genbank or embl files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_guid_file = open('example_guide_table.txt','wt')\n",
      "#data type dna/prot\n",
      "example_guid_file.write('dna\\n')\n",
      "#type -> name1,name2,...,name j type= gene/CDS/rRNA/tRNA\n",
      "example_guid_file.write('CDS\\tcox1,COX1,coi,COI,CoI\\n')\n",
      "example_guid_file.write('CDS\\tnd5,ND5,nadh5,NADH5\\n')\n",
      "example_guid_file.write('rRNA\\t18s,18S,SSU,18S ribosomal RNA\\n')\n",
      "\n",
      "example_guid_file.close()\n",
      "\n",
      "example_guid_file_string = open('example_guide_table.txt','r').read()\n",
      "print example_guid_file_string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dna\n",
        "CDS\tcox1,COX1,coi,COI,CoI\n",
        "CDS\tnd5,ND5,nadh5,NADH5\n",
        "rRNA\t18s,18S,SSU,18S ribosomal RNA\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take guide file\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_featuretype(Type):\n",
      "    if not (Type == 'gene' or Type == 'CDS' or Type == 'rRNA' or Type == 'tRNA'):\n",
      "        return False\n",
      "    else:\n",
      "        return True\n",
      "\n",
      "def is_datatype(Type):\n",
      "    if not (Type == 'dna' or Type == 'prot'):\n",
      "        return False\n",
      "    else:\n",
      "        return True    \n",
      "\n",
      "def build_data_dict(guid_file_name):\n",
      "    guid_file_lines = open(guid_file_name, 'r').readlines()\n",
      "    datasets_to_get = {}\n",
      "    datases_count = 0\n",
      "    datatype = ''\n",
      "    if is_datatype(guid_file_lines[0].rstrip()):\n",
      "        datasets_to_get['datatype'] = guid_file_lines[0].rstrip()\n",
      "        datatype = guid_file_lines[0].rstrip()\n",
      "        guid_file_lines = guid_file_lines[1:]\n",
      "        print 'Datatype ', datasets_to_get['datatype']\n",
      "    else:\n",
      "        sys.exit('Datatype has to be dna or prot')\n",
      "    \n",
      "    exp = 0\n",
      "    \n",
      "    for line in guid_file_lines:\n",
      "        if is_featuretype(line.split('\t')[0]):\n",
      "            datasets_to_get['dataset' + str(datases_count)] = {'type': line.split('\t')[0],\n",
      "                                                               'names': line.rstrip().split('\t')[1].split(','),\n",
      "                                                               'records': [],\n",
      "                                                               'filename': ''}\n",
      "            datases_count += 1\n",
      "            print line, 'OK'\n",
      "        else:\n",
      "            exp = 1\n",
      "            raise Exception('Unsupported feature type in ', line)\n",
      "    \n",
      "    if exp == 1:\n",
      "        print 'Supported feature types: gene, CDS, rRNA and tRNA'\n",
      "    return datasets_to_get\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take input(s) if genbank or embl\n",
      "----------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys\n",
      "from Bio import SeqIO\n",
      "\n",
      "def guess_format(input_filename):\n",
      "    if os.path.exists(input_filename):\n",
      "        os.system('perl guesser.pl ' + input_filename)\n",
      "        guess = open(input_filename + '.format','r').read();\n",
      "        os.remove(input_filename + '.format')\n",
      "        return guess\n",
      "    else:\n",
      "        sys.exit('Cannot guess ' + input_filename + '. Does it exist?')\n",
      "    \n",
      "def is_embl_or_gb(input_filename):\n",
      "    input_format = guess_format(input_filename)\n",
      "    if input_format == 'embl' or input_format == 'genbank':\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "def parse_input(input_filename):\n",
      "    return SeqIO.parse(input_filename, guess_format(input_filename))\n",
      "\n",
      "def read_embl_genbank(input_filenames_list):\n",
      "    generators = []\n",
      "    for input_filename in input_filenames_list:\n",
      "        if is_embl_or_gb(input_filename):\n",
      "            generators.append(parse_input(input_filename))\n",
      "            print 'Accepted:', input_filename\n",
      "        else:\n",
      "            print ('Rejected: ' + input_filename + ' is ' + \n",
      "                    guess_format(input_filename) + ' . Should be genbank or embl.')\n",
      "    return generators"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get the features\n",
      "----------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def translation_exists(record_feature):\n",
      "    if 'translation' in record_feature.qualifiers.keys():\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "def get_translation(record_feature):\n",
      "    if translation_exists(record_feature):\n",
      "        return record_feature.qualifiers['translation']\n",
      "    else:\n",
      "        return False\n",
      "    \n",
      "from Bio.Seq import Seq\n",
      "from Bio.Alphabet import IUPAC\n",
      "\n",
      "def make_prot_seq_object(prot_seq_string):\n",
      "    return Seq(seq_string, IUPAC.protein)\n",
      "\n",
      "from Bio.SeqRecord import SeqRecord\n",
      "\n",
      "def make_subseqrecord(seq_record, record_feature, datatype):\n",
      "    subseq_object = None\n",
      "    if datatype == 'dna':\n",
      "        subseq_object = record_feature.extract(seq_record.seq)\n",
      "    elif datatype == 'prot':\n",
      "        prot_seq_string = get_translation(record_feature)\n",
      "        subseq_object = make_prot_seq_object(prot_seq_string)\n",
      "    subrecord = SeqRecord(subseq_object, id=seq_record.id, description = seq_record.description)\n",
      "    subrecord.annotations['organism']  = seq_record.annotations['organism'] \n",
      "    return subrecord\n",
      "\n",
      "\n",
      "\n",
      "def iter_features(seq_record, datasets_to_get):\n",
      "    for i in range(len(seq_record.features)):\n",
      "        feature = seq_record.features[i]\n",
      "        dataset_names = datasets_to_get.keys()\n",
      "        dataset_names.pop(dataset_names.index('datatype'))\n",
      "        feature_qualifiers = feature.qualifiers.keys()\n",
      "        gene_or_product = False\n",
      "        if 'gene' in feature_qualifiers:\n",
      "            gene_or_product = 'gene'\n",
      "        elif 'product' in feature_qualifiers:\n",
      "            gene_or_product = 'product'\n",
      "        if gene_or_product:\n",
      "            for dataset_name in dataset_names:\n",
      "                if (datasets_to_get[dataset_name]['type'] == feature.type and \n",
      "                    feature.qualifiers[gene_or_product][0] in datasets_to_get[dataset_name]['names']):\n",
      "                    sub_record = make_subseqrecord(seq_record, feature, datasets_to_get['datatype'])\n",
      "                    datasets_to_get[dataset_name]['records'].append(sub_record)\n",
      "    return datasets_to_get\n",
      "\n",
      "def iter_records(generator, datasets_to_get):\n",
      "    for seq_record in generator:\n",
      "        datasets_to_get = iter_features(seq_record, datasets_to_get)\n",
      "    return datasets_to_get\n",
      "                \n",
      "def iter_generators(generators, datasets_to_get):\n",
      "    for generator in generators:\n",
      "        datasets_to_get = iter_records(generator, datasets_to_get)\n",
      "    return datasets_to_get"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write fasta files\n",
      "-----------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_fasta_file_from(datasets_to_get, path='./'):\n",
      "    if not path[-1] == '/':\n",
      "        path = path + '/'\n",
      "    dataset_names = datasets_to_get.keys()\n",
      "    dataset_names.pop(dataset_names.index('datatype'))\n",
      "    for dataset in dataset_names:\n",
      "        out_fasta_name = dataset + '_' + datasets_to_get[dataset]['names'][0] + '.fasta'\n",
      "        SeqIO.write(datasets_to_get[dataset]['records'], path + out_fasta_name, 'fasta')\n",
      "        datasets_to_get[dataset]['filename'] = out_fasta_name\n",
      "    return datasets_to_get"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check datasets for missing sequences\n",
      "------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_all_species(datasets_to_get):\n",
      "    all_records = []\n",
      "    dataset_names = datasets_to_get.keys()\n",
      "    dataset_names.pop(dataset_names.index('datatype'))\n",
      "    for dataset in dataset_names:\n",
      "        all_records = all_records + datasets_to_get[dataset]['records']\n",
      "    all_species = []\n",
      "    for record in all_records:\n",
      "        if not record.annotations['organism'] in all_species:\n",
      "            all_species.append(record.annotations['organism'])\n",
      "    return all_species\n",
      "\n",
      "def check_datasets(datasets_to_get):\n",
      "    all_species = get_all_species(datasets_to_get)\n",
      "    all_datasets = datasets_to_get.keys()\n",
      "    all_datasets.pop(all_datasets.index('datatype'))\n",
      "    missing_data = {}\n",
      "    for species in all_species:\n",
      "        missing_data[species] = []\n",
      "        for dataset in all_datasets:\n",
      "            missing = 1\n",
      "            for record in datasets_to_get[dataset]['records']:\n",
      "                if record.annotations['organism'] == species:\n",
      "                    missing = 0\n",
      "            if missing == 1:\n",
      "                missing_data[species].append(datasets_to_get[dataset]['filename'])\n",
      "    for species in missing_data.keys():\n",
      "        if len(missing_data[species]) > 0:\n",
      "            print species, 'missing from:'\n",
      "            for i in missing_data[species]:\n",
      "                print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=red>Actual action</font>:\n",
      "====================================\n",
      "<br>\n",
      "Make fasta form genbank files\n",
      "-----------------------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Build empy dict**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets_to_get = build_data_dict('example_guide_table.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Datatype  dna\n",
        "CDS\tcox1,COX1,coi,COI,CoI\n",
        "OK\n",
        "CDS\tnd5,ND5,nadh5,NADH5\n",
        "OK\n",
        "rRNA\t18s,18S,SSU,18S ribosomal RNA\n",
        "OK\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Make SeqIO generators form the genbank input files**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_folder = '/media/amir/DATA/work/Dropbox/ReproPhylo/data/'\n",
      "input_filenames_list = (data_folder + 'primates.gb',\n",
      "                        data_folder + 'primates1.gb')\n",
      "generators = read_embl_genbank(input_filenames_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accepted: /media/amir/DATA/work/Dropbox/ReproPhylo/data/primates.gb\n",
        "Accepted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " /media/amir/DATA/work/Dropbox/ReproPhylo/data/primates1.gb\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Add the records to the empty dict**\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets_to_get = iter_generators(generators, datasets_to_get)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Print fasta files**\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets_to_get = write_fasta_file_from(datasets_to_get, path='./data')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Search for missing data points**\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_datasets(datasets_to_get)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Macaca mulatta missing from:\n",
        "dataset0_cox1.fasta\n",
        "dataset1_nd5.fasta\n",
        "Macaca mulatta lasiotus missing from:\n",
        "dataset2_18s.fasta\n"
       ]
      }
     ],
     "prompt_number": 146
    }
   ],
   "metadata": {}
  }
 ]
}