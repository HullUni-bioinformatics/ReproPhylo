{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# make_reprophylo_database\n",
      "## using a loci file\n",
      "## and optionaly a gb or embl file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file example_loci_file.txt\n",
      "# defines the loci to pick up from the genbank file\n",
      "# usage\n",
      "# mol_type,feature_type,name,alias-1,alias-2,...,alias-n\n",
      "# Spaces ONLY allowed in aliases\n",
      "\n",
      "dna,rRNA,18S,18s,18S,SSU rRNA,18S ribosomal RNA\n",
      "\n",
      "dna,rRNA,28S,28s,28S,LSU rRNA,28S ribosomal RNA,28S large subunit ribosomal RNA\n",
      "\n",
      "dna,CDS,coi,cox1,COX1,coi,COI,CoI"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing example_loci_file.txt\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file make_reprophylo_database.py\n",
      "\n",
      "def parse_loci_file(loci_filename):\n",
      "    # get rid of comments and blank lines\n",
      "    loci = []\n",
      "    lines = []\n",
      "    for line in open(loci_filename,'r').readlines():\n",
      "        if not line[0] == '#' and not line[0] == '\\n':\n",
      "            lines.append(line.rstrip())\n",
      "    \n",
      "    available_commands = ['dna','prot']\n",
      "    \n",
      "    for line in lines:\n",
      "        # parse a locus\n",
      "        if line[0:3] == 'dna' or ine[0:4] == 'prot':\n",
      "            parts = line.split(',')\n",
      "            loci.append(Locus(parts[0],parts[1],parts[2], parts[3:]))\n",
      "    return loci    \n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "loci_file_name = sys.argv[1]\n",
      "output_name = sys.argv[2]\n",
      "genbank_file_name = None\n",
      "if len(sys.argv) == 4:\n",
      "    genbank_file_name = sys.argv[3]\n",
      "    \n",
      "loci =  parse_loci_file(loci_file_name)       \n",
      "\n",
      "db = Database(loci)\n",
      "\n",
      "if genbank_file_name: \n",
      "    db.read_embl_genbank([genbank_file_name])\n",
      "\n",
      "output = open(output_name,'wb')\n",
      "pickle.dump(db, output)\n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting make_reprophylo_database.py\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# command line usage\n",
      "#! python ./make_reprophylo_database.py example_loci_file.txt test_rp_db.pkl\n",
      "# OR\n",
      "#! python ./make_reprophylo_database.py example_loci_file.txt test_rp_db.pkl data/Tetillidae.gb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file make_reprophylo_database.xml\n",
      "\n",
      "<tool id=\"make_reprophylo_database\" name=\"generate reprophylo databse\" version=\"0.1\" hidden=\"false\">\n",
      "    <description>Start a skeleton ReproPhylo DB based on a loci file.\n",
      "    Optionaly include sequence data from an embl or genbank file\n",
      "    </description>\n",
      "    <command interpreter=\"python\">\n",
      "        #if $genbank.add_database_data_file==\"yes\"\n",
      "            make_reprophylo_database.py  $locifile $ReproPhylo_DB_file $input\n",
      "        #else\n",
      "            make_reprophylo_database.py  $locifile $ReproPhylo_DB_file\n",
      "        #end if\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"locifile\" type=\"data\" label=\"loci file\"/>\n",
      "        <conditional name=\"genbank\">\n",
      "            <param name=\"add_database_data_file\" type=\"select\" label=\"include embl or genbank file?\">\n",
      "                <option value=\"no\">no</option>\n",
      "                <option value=\"yes\">yes</option>\n",
      "            </param>\n",
      "            <when value=\"no\"/>\n",
      "            <when value=\"yes\">\n",
      "                <param name=\"input\" type=\"data\" label=\"genbank or embl file\"/>\n",
      "            </when>\n",
      "        </conditional>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"ReproPhylo_DB_file\" label=\"${tool.name} on ${on_string}: ReproPhylo DB file (.pkl)\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting make_reprophylo_database.xml\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# read_denovo_data\n",
      "## from a fasta file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file read_denovo_data.py\n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "denovo_filename = [sys.argv[2]]\n",
      "char_type = sys.argv[3]\n",
      "picke_output = sys.argv[4]\n",
      "\n",
      "pickle_handle = open(pickle_input, 'rb')\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "db.read_denovo(denovo_filename, char_type)\n",
      "\n",
      "output = open(picke_output,'wb')\n",
      "pickle.dump(db, output)\n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing read_denovo_data.py\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# command line usage\n",
      "#! python ./read_denovo_data.py test_rp_db.pkl data/Tetillidae_denovo_sequence.fasta dna test_rp_db_1.pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file read_denovo_data.xml\n",
      "\n",
      "<tool id=\"read_denovo_data\" name=\"read denovo data\" version=\"0.1\" hidden=\"false\">\n",
      "    <description>Read denovo data from an unaligned fasta file.\n",
      "    The file have to be either DNA or Protein but not mixed. Can run twice,\n",
      "    once with DNA and once with prot.\n",
      "    </description>\n",
      "    <command interpreter=\"python\">\n",
      "        read_denovo_data.py  $picklein $fasta $chartype $ReproPhylo_DB_file\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"picklein\" type=\"data\" label=\"ReproPhylo DB file (.pkl)\"/>\n",
      "        <param name=\"fasta\" type=\"data\" label=\"fasta file\"/>\n",
      "        <param name=\"chartype\" type=\"select\" label=\"sequence type\">\n",
      "            <option value=\"dna\">nucleotide</option>\n",
      "            <option value=\"prot\">protein</option>\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"ReproPhylo_DB_file\" label=\"${tool.name} on ${on_string}: ReproPhylo DB file (.pkl)\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting read_denovo_data.xml\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#export_reprophylo_db"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file export_reprophylo_db.py\n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "export_format = sys.argv[2]\n",
      "expot_filname = sys.argv[3]\n",
      "\n",
      "pickle_handle = open(pickle_input, 'rb')\n",
      "\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "db.write(expot_filname, format = export_format)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting export_reprophylo_db.py\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#! python ./export_reprophylo_db.py test_rp_db_1.pkl genbank test_rp_db_1.gb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file export_reprophylo_db.xml\n",
      "\n",
      "<tool id=\"export_reprophylo_db\" name=\"export_reprophylo_db\" version=\"0.1\" hidden=\"false\">\n",
      "    <description>dump your sequence records into a csv file or gb file to review the feature qualifiers</description>\n",
      "    <command interpreter=\"python\">\n",
      "        export_reprophylo_db.py $pickle_input $export_format $exported_ReproPhylo_DB\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"pickle_input\" type=\"data\" label=\"ReproPhylo DB file (.pkl)\" >\n",
      "        </param>\n",
      "        <param name=\"export_format\" type=\"select\" label=\"export_format\" >\n",
      "           <option value=\"csv\">csv</option>\n",
      "           <option value=\"genbank\">genbank</option>\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"exported_ReproPhylo_DB\" format=\"txt\" type=\"data\" label=\"${tool.name} on ${on_string}: gb or csv\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting export_reprophylo_db.xml\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Edit record features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file example_edit_features.txt\n",
      "\n",
      "# Edit record features\n",
      "# Edits will take place in order: Add a feature last, it will have non of the preceding edits\n",
      "\n",
      "\n",
      "# add_feature\n",
      "# adds a feature to an existing record\n",
      "# usage\n",
      "# add_feature,record_id,feature type,start1 end1 strand1 start2 end2 strand2 startn endn strandn,qualifier1,value1,qualifier2,value2,qualifiern,valuen\n",
      "# remark: starts and ends are real, not computer count (ie start with 1), strand takes 1 or -1\n",
      "add_feature,denovo0,CDS,1 786 1 1742 2092 1,gene,cox1,product,cytochrome c oxidase subunit I,codon_start,1,transl_table,4,organism,Craniella microsigma\n",
      "\n",
      "\n",
      "# add_qualifier_from_source\n",
      "# copies a qualifier from the source feature to all the other features so that it can be edited.\n",
      "# source feature qualifiers cannot be edited in place to protect integrity.\n",
      "# usage\n",
      "# add_qualifier_from_source,qualifier_keyword\n",
      "add_qualifier_from_source,organism\n",
      "\n",
      "# ifttt (if this than that)\n",
      "# fooks for value a in qualifier x and than puts b in qualifier y (a == b and x == y is allowed)\n",
      "# usage\n",
      "# ifttt,searched_value(a),searched_qualifier(x),introuced_value(b),edited_qualifier(y)\n",
      "ifttt,Cinachyrella,organism,Cinachyrella,genus,part\n",
      "ifttt,Cinachyra,organism,Cinachyra,genus,part\n",
      "ifttt,Amphitethya,organism,Amphitethya,genus,part\n",
      "ifttt,Paratetilla,organism,Paratetilla,genus,part\n",
      "ifttt,Acanthotetilla,organism,Acanthotetilla,genus,part\n",
      "ifttt,Tetilla,organism,Tetilla,genus,part\n",
      "ifttt,Craniella,organism,Craniella,genus,part\n",
      "ifttt,Fangophilina,organism,Fangophilina,genus,part\n",
      "\n",
      "ifttt,Geodia,organism,Astrophorida,genus,part\n",
      "ifttt,Pachymatisma,organism,Astrophorida,genus,part\n",
      "ifttt,Calthropella,organism,Astrophorida,genus,part\n",
      "ifttt,Thenea,organism,Astrophorida,genus,part\n",
      "ifttt,Theonella,organism,Astrophorida,genus,part\n",
      "\n",
      "ifttt,18S ribosomal RNA,product,SSU rRNA,gene\n",
      "ifttt,28S ribosomal RNA,product,LSU rRNA,gene\n",
      "ifttt,AM076987.1_f1,feature_id,LAGLIDADG,gene\n",
      "\n",
      "\n",
      "# add_qualifier_from_source\n",
      "# copies a qualifier from the source feature to all the other features so that it can be edited.\n",
      "# source feature qualifiers cannot be edited in place to protect integrity.\n",
      "# usage\n",
      "# add_qualifier_from_source,qualifier_keyword\n",
      "add_qualifier_from_source,specimen_voucher\n",
      "\n",
      "# add qulaifier\n",
      "# adds qualifier x with value a to indicated feature(s) z\n",
      "# usage\n",
      "# add_qualifier,feature(s)(z),qualifier(x),value(b)\n",
      "add_qualifier,JX177968.1_f0,specimen_voucher,QMG_321405\n",
      "add_qualifier,JX177913.1_f0,JX177935.1_f0,JX177965.1_f0,specimen_voucher,TAU_25617\n",
      "add_qualifier,JX177903.1_f0,JX177938.1_f0,specimen_voucher,TAU_25618\n",
      "add_qualifier,HM032740.1_f0,JX177964.1_f0,specimen_voucher,TAU_25621\n",
      "add_qualifier,HM032739.1_f0,JX177962.1_f0,specimen_voucher,TAU_25622\n",
      "add_qualifier,JX177968.1_f0,specimen_voucher,QMG_321405\n",
      "add_qualifier,JX177891.1_f0,specimen_voucher,RMNH_POR_3100\n",
      "add_qualifier,JX177900.1_f0,JX177926.1_f0,specimen_voucher,TAU_25620\n",
      "add_qualifier,JX177901.1_f0,JX177956.1_f0,JX177961.1_f0,specimen_voucher,TAU_25619\n",
      "add_qualifier,HM032742.1_f0,JX177957.1_f0,specimen_voucher,MNRJ_576\n",
      "\n",
      "\n",
      "# ifttt (if this than that)\n",
      "# fooks for value a in qualifier x and than puts b in qualifier y (a == b and x == y is allowed)\n",
      "# usage\n",
      "# ifttt,searched_value(a),searched_qualifier(x),introuced_value(b),edited_qualifier(y)\n",
      "ifttt,QMG321405,specimen_voucher,QMG_321405,specimen_voucher\n",
      "ifttt,MHNM16194,specimen_voucher,MHNM_16194,specimen_voucher\n",
      "ifttt,TAU25456,specimen_voucher,TAU_25456,specimen_voucher\n",
      "ifttt,QMG320636,specimen_voucher,QMG_320636,specimen_voucher\n",
      "ifttt,QMG320270,specimen_voucher,QMG_320270,specimen_voucher\n",
      "ifttt,ZMBN:85239,specimen_voucher,ZMBN_85239,specimen_voucher\n",
      "ifttt,QMG318785,specimen_voucher,QMG_318785,specimen_voucher\n",
      "ifttt,QMG316342,specimen_voucher,QMG_316342,specimen_voucher\n",
      "ifttt,QMG314224,specimen_voucher,QMG_314224,specimen_voucher\n",
      "ifttt,VM14754,specimen_voucher,VM_14754,specimen_voucher\n",
      "ifttt,ZMBN:85240,specimen_voucher,ZMBN_85240,specimen_voucher\n",
      "ifttt,ZMBN:81789,specimen_voucher,ZMBN_81789,specimen_voucher\n",
      "ifttt,ZMBN:81787,specimen_voucher,ZMBN_81787,specimen_voucher\n",
      "ifttt,ZMBN:81785,specimen_voucher,ZMBN_81785,specimen_voucher\n",
      "\n",
      "# copy_paste_within_feature\n",
      "# copies a value from one qualifier to another in the indicated features\n",
      "# usage\n",
      "# copy_paste_within_feature,qualifer_to_copy_from,qualifier_to_copy_to\n",
      "# remark: qualifier_to_copy_to does not have to exist prior to invocation of this function\n",
      "copy_paste_within_feature,specimen_voucher,OTU_dict\n",
      "\n",
      "# add qulaifier\n",
      "# adds qualifier x with value a to indicated feature(s) z\n",
      "# usage\n",
      "# add_qualifier feature(s)(z),qualifier(x),value(b)\n",
      "add_qualifier,AY737635.1_f0,AY320032.1_f0,OTU_dict,Geodia_neptuni\n",
      "add_qualifier,EF564339.1_f0,HM592832.1_f0,OTU_dict,Pachymatisma_johnstonia\n",
      "add_qualifier,HM592717.1_f0,HM592765.1_f0,OTU_dict,Thenea_levis\n",
      "add_qualifier,HM592745.1_f0,HM592820.1_f0,OTU_dict,Theonella_swinhoei\n",
      "add_qualifier,KC762708.1_f0,NC_010198.1_f0,OTU_dict,Cinachyrella_kuekenthali\n",
      "add_qualifier,HM592705.1_f0,HM592826.1_f0,OTU_dict,Calthropella_geodioides\n",
      "\n",
      "ifttt,Cinachyrella,genus,2,porocalices\n",
      "ifttt,Cinachyra,genus,2,porocalices\n",
      "ifttt,Paratetilla,genus,2,porocalices\n",
      "ifttt,Fangophilina,genus,2,porocalices\n",
      "ifttt,Acanthotetilla,genus,2,porocalices\n",
      "ifttt,Amphitethya,genus,2,porocalices\n",
      "ifttt,Tetilla,genus,1,porocalices\n",
      "ifttt,Craniella,genus,1,porocalices\n",
      "ifttt,Craniella,genus,2,cortex\n",
      "ifttt,Cinachyra,genus,2,cortex\n",
      "ifttt,Fangophilina,genus,2,cortex\n",
      "ifttt,Cinachyrella,genus,1,cortex\n",
      "ifttt,Tetilla,genus,1,cortex\n",
      "ifttt,Paratetilla,genus,1,cortex\n",
      "ifttt,Acanthotetilla,genus,1,cortex\n",
      "ifttt,Amphitethya,genus,1,cortex\n",
      "ifttt,Paratetilla,genus,2,calthrops\n",
      "ifttt,Cinachyrella,genus,1,calthrops\n",
      "ifttt,Cinachyra,genus,1,calthrops\n",
      "ifttt,Fangophilina,genus,1,calthrops\n",
      "ifttt,Acanthotetilla,genus,1,calthrops\n",
      "ifttt,Amphitethya,genus,1,calthrops\n",
      "ifttt,Tetilla,genus,1,calthrops\n",
      "ifttt,Craniella,genus,1,calthrops\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting example_edit_features.txt\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file edit_features.py\n",
      "\n",
      "def parse_control_file(control_filename):\n",
      "    # get rid of comments and blank lines\n",
      "    edit_commands = []\n",
      "    lines = []\n",
      "    for line in open(control_filename,'r').readlines():\n",
      "        if not line[0] == '#' and not line[0] == '\\n':\n",
      "            lines.append(line.rstrip())\n",
      "    \n",
      "    available_commands = ['add_feature','ifttt','add_qualifier','add_qualifier_from_source',\n",
      "                         'copy_paste_within_feature','copy_paste_from_features_to_source']\n",
      "    \n",
      "    for line in lines:\n",
      "            parts = line.split(',')\n",
      "            command = parts[0]\n",
      "            if command in available_commands:\n",
      "                edit_commands.append(parts)\n",
      "            else:\n",
      "                raise RuntimeError(command+' is an unknown command')\n",
      "                \n",
      "    return edit_commands\n",
      "\n",
      "def execute_edit_commands(edit_commands_list, db):\n",
      "    for command in edit_commands_list:\n",
      "        if command[0] == 'ifttt':\n",
      "            if len(command) == 6:\n",
      "                db.if_this_then_that(command[1],command[2],command[3],command[4],command[5])\n",
      "            elif len(command) == 5:\n",
      "                db.if_this_then_that(command[1],command[2],command[3],command[4])\n",
      "            else:\n",
      "                raise RuntimeError('command ifttt takes at least 4 args. '+\n",
      "                                   str(len(command)-1)+' are provided')\n",
      "        elif command[0] == 'add_qualifier':\n",
      "            if len(command) >= 4:\n",
      "                db.add_qualifier(command[:-2],command[-2],command[-1])\n",
      "            else:\n",
      "                raise RuntimeError('command add_qualifier takes at least 3 args. '+\n",
      "                                   str(len(command)-1)+' are provided')\n",
      "        elif command[0] == 'add_qualifier_from_source':\n",
      "            if len(command) == 2:\n",
      "                db.add_qualifier_from_source(command[1])\n",
      "            else:\n",
      "                raise RuntimeError('command add_qualifier_from_source takes exactly 1 arg. '+\n",
      "                                   str(len(command)-1)+' are provided')\n",
      "        elif command[0] == 'copy_paste_within_feature':\n",
      "            if len(command) == 3:\n",
      "                db.copy_paste_within_feature(command[1],command[2])\n",
      "            else:\n",
      "                raise RuntimeError('command add_qualifier_from_source takes exactly 2 args. '+\n",
      "                                   str(len(command)-1)+' are provided')\n",
      "        elif command[0] == 'copy_paste_from_features_to_source':\n",
      "            if len(command) == 3:\n",
      "                db.copy_paste_from_features_to_source(command[1],command[2])\n",
      "            else:\n",
      "                raise RuntimeError('command copy_paste_from_features_to_source takes exactly 2 args. '+\n",
      "                                   str(len(command)-1)+' are provided')\n",
      "        elif command[0] == 'add_feature':\n",
      "            record_id = command[1]\n",
      "            feature_type = command[2]\n",
      "            if not isinstance(feature_type,str):\n",
      "                raise IOError('feature type must be a string')\n",
      "            location_values = command[3]\n",
      "            while location_values[0] == ' ':\n",
      "                location_values = location_values[1:]\n",
      "            while location_values[-1] == ' ':\n",
      "                location_values = location_values[:-1]\n",
      "            location_values_list = location_values.split(' ')\n",
      "            if len(location_values_list)%3 > 0:\n",
      "                raise IOError('feature location values must be triplets:start end strand')\n",
      "            location_values_list = [int(x) for x in location_values_list]\n",
      "            location = []\n",
      "            while location_values_list:\n",
      "                l = location_values_list[:3]\n",
      "                location_values_list = location_values_list[3:]\n",
      "                if l[1] < l[0]:\n",
      "                    raise IOError('Start position must be smaller then End position')\n",
      "                if ((not l[2] == 1) and (not l[2] == -1)):\n",
      "                    raise IOError('Strand must be 1 or -1')\n",
      "                location.append(l)\n",
      "            qualifiers_in_list = command[4:]\n",
      "            if len(qualifiers_in_list)%2 > 0:\n",
      "                raise IOError('The number of qualifiers and their values do not match')\n",
      "            qualifiers = {}\n",
      "            while qualifiers_in_list:\n",
      "                try:\n",
      "                    qualifiers[qualifiers_in_list[0]] = int(qualifiers_in_list[1])\n",
      "                except:\n",
      "                    qualifiers[qualifiers_in_list[0]] = qualifiers_in_list[1]\n",
      "                qualifiers_in_list = qualifiers_in_list[2:]\n",
      "            db.add_feature_to_record(record_id, feature_type, location=location, qualifiers=qualifiers)\n",
      "        else:\n",
      "            raise RuntimeError('command '+command[0]+' is not recognised')\n",
      "# add_feature,record_id,feature type,start1 end1 strand1 start2 end2 strand2 startn endn strandn,qualifier1,value1,qualifier2,value2,qualifiern,valuen\n",
      "    \n",
      "\n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "control_file_name = sys.argv[2]\n",
      "pickle_output = sys.argv[3]\n",
      "\n",
      "pickle_handle = open(pickle_input, 'rb')\n",
      "\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "edit_commands =  parse_control_file(control_file_name)       \n",
      "\n",
      "execute_edit_commands(edit_commands, db)\n",
      "\n",
      "output = open(pickle_output,'wb')\n",
      "pickle.dump(db, output)\n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting edit_features.py\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#! python ./edit_features.py test_rp_db_1.pkl example_edit_features.txt test_rp_db_2.pkl\n",
      "#! python ./export_reprophylo_db.py test_rp_db_2.pkl genbank test_rp_db_2.gb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file edit_record_features.xml\n",
      "\n",
      "<tool id=\"edit_record_features\" name=\"edit_record_features\" version=\"0.1\" hidden=\"false\">\n",
      "    <description>some description</description>\n",
      "    <command interpreter=\"python\">\n",
      "        edit_features.py $pickle_input $controlfile $ReproPhylo_DB_file\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"pickle_input\" type=\"data\" label=\"ReproPhylo DB file (.pkl)\" >\n",
      "        </param>\n",
      "         <param name=\"controlfile\" type=\"data\" label=\"edit commands file\" >\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"ReproPhylo_DB_file\" label=\"${tool.name} on ${on_string}: ReproPhylo DB file (.pkl)\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting edit_record_features.xml\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Sequence Alignment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file example_seq_aln_file.txt\n",
      "# Set\n",
      "# group of loci\n",
      "# usage:\n",
      "#set,name,locus1,locus2,...,locusn\n",
      "set,rRNA_loci,18S,28S\n",
      "\n",
      "# Program\n",
      "# Set path to program\n",
      "# usage:\n",
      "# program,program_name,path/to/program/program_name\n",
      "program,mafft,mafft\n",
      "program,muscle,muscle\n",
      "program,pal2nal,/home/amir/Dropbox/ReproPhylo/pal2nal.pl\n",
      "\n",
      "# Method\n",
      "# Assign alignment method to a locus or a set of loci or all the loci\n",
      "# Usage:\n",
      "# method,method_name,locus/set/all,program,CodonYes/CodonNo,cline_arg1,value1,cline_arg2,value2,...,cline_arg3,value3\n",
      "\n",
      "method,Linsi,coi,mafft,CodonYes,localpair,True,maxiterate,1000\n",
      "method,MuscleDefaults,rRNA_loci,muscle,CodonYes\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting example_seq_aln_file.txt\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file sequence_alignment.py\n",
      "\n",
      "def parse_control_file(control_filename):\n",
      "    programs = {}\n",
      "    sets = {}\n",
      "    methods = {}\n",
      "    lines = []\n",
      "    # get rid of comments and blank lines\n",
      "    for line in open(control_filename,'r').readlines():\n",
      "        if not line[0] == '#' and not line[0] == '\\n':\n",
      "            lines.append(line.rstrip())\n",
      "    \n",
      "    available_commands = ['program','set','method']\n",
      "    \n",
      "    for line in lines:\n",
      "            parts = line.split(',')\n",
      "            command = parts[0]\n",
      "            if command == 'program':\n",
      "                programs[parts[1]] = parts[2]\n",
      "            elif command == 'set':\n",
      "                sets[parts[1]] = parts[2:]\n",
      "            elif command == 'method':\n",
      "                cline_args = None\n",
      "                if len(parts) > 5:\n",
      "                    cline_args = parts[5:]\n",
      "                methods[parts[1]] = {'loci': parts[2],\n",
      "                                     'program_name': parts[3],\n",
      "                                     'codon_align': parts[4],\n",
      "                                     'cline_args': cline_args}\n",
      "            else:\n",
      "                raise RuntimeError(command+' is an unknown command')\n",
      "                \n",
      "    return programs, sets, methods\n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "control_file_name = sys.argv[2]\n",
      "pickle_output = sys.argv[3]\n",
      "\n",
      "pickle_handle = open(pickle_input, 'rb')\n",
      "\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "db.extract_by_locus()\n",
      "\n",
      "print 'loci in db: ' + str(db.records_by_locus.keys())\n",
      "\n",
      "loci_names = []\n",
      "\n",
      "for locus in db.loci:\n",
      "    loci_names.append(locus.name)\n",
      "\n",
      "programs, sets, methods = parse_control_file(control_file_name)\n",
      "\n",
      "alignment_method_objects = []\n",
      "\n",
      "for method in methods.keys():\n",
      "    CDSAlign = False\n",
      "    indicated_method_loci = methods[method]['loci']\n",
      "    loci_to_use = []\n",
      "    if indicated_method_loci == 'all':\n",
      "        loci_to_use = loci_names\n",
      "    elif indicated_method_loci in sets.keys():\n",
      "        loci_to_use = sets[indicated_method_loci]\n",
      "    elif indicated_method_loci in loci_names:\n",
      "        loci_to_use = [indicated_method_loci]\n",
      "    elif isinstance(indicated_method_loci,list):\n",
      "        raise IOError('loci for alignment method must be indicated by one locus name or one set name.'+\n",
      "                      ' List not accepted')\n",
      "    else:\n",
      "        raise IOError(indicated_method_loci + ' is not a recognized locus or set')\n",
      "    if methods[method]['codon_align'] == 'CodonYes':\n",
      "        CDSAlign = True\n",
      "    elif  methods[method]['codon_align'] == 'CodonNo':\n",
      "        CDSAlign = False\n",
      "    else:\n",
      "        raise IOError(methods[method]['codon_align']+' is not a recognised argument')\n",
      "    cline_args = dict()\n",
      "    cline_args_dict = {}\n",
      "    if methods[method]['cline_args']:\n",
      "        if len(methods[method]['cline_args'])%2 > 0:\n",
      "            raise IOError('The number of cline args do no match the number of values in method '+method)\n",
      "        while methods[method]['cline_args']:\n",
      "            try:\n",
      "                cline_args_dict[methods[method]['cline_args'][0]] = int(methods[method]['cline_args'][1])\n",
      "            except:\n",
      "                try:\n",
      "                    cline_args_dict[methods[method]['cline_args'][0]] = float(methods[method]['cline_args'][1])\n",
      "                except:\n",
      "                    cline_args_dict[methods[method]['cline_args'][0]] = methods[method]['cline_args'][1]\n",
      "            methods[method]['cline_args'] = methods[method]['cline_args'][2:]\n",
      "    print 'building method ' + method\n",
      "    print 'method loci ' + str(loci_to_use)\n",
      "    print 'codon alignment ' + str(CDSAlign)\n",
      "    print 'program name ' + methods[method]['program_name']\n",
      "    print 'cmd ' + programs[methods[method]['program_name']]\n",
      "    print 'args '+ str(cline_args_dict)\n",
      "    print\n",
      "    alignment_method_object = AlignmentMethod(db, \n",
      "                                              method_name=method,\n",
      "                                              CDSAlign=CDSAlign,\n",
      "                                              program_name=methods[method]['program_name'],\n",
      "                                              cmd=programs[methods[method]['program_name']],\n",
      "                                              loci = loci_to_use,\n",
      "                                              cline_args=cline_args_dict)\n",
      "\n",
      "    alignment_method_objects.append(alignment_method_object)\n",
      "\n",
      "db.align(alignment_methods=alignment_method_objects, pal2nal=programs['pal2nal'])\n",
      "\n",
      "import cloud.serialization.cloudpickle as pickle\n",
      "output = open(pickle_output,'wb')\n",
      "pickle.dump(db, output)\n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting sequence_alignment.py\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! python ./sequence_alignment.py test_rp_db_2.pkl example_seq_aln_file.txt test_rp_db_3.pkl "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loci in db: ['coi', '18S', '28S']\r\n",
        "building method Linsi\r\n",
        "method loci ['coi']\r\n",
        "codon alignment True\r\n",
        "program name mafft\r\n",
        "cmd mafft\r\n",
        "args {'localpair': 'True', 'maxiterate': 1000}\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mafft --localpair --maxiterate 1000 585281403812395.17_CDS_proteins_coi.fasta\r\n",
        "building method MuscleDefaults\r\n",
        "method loci ['18S', '28S']\r\n",
        "codon alignment True\r\n",
        "program name muscle\r\n",
        "cmd muscle\r\n",
        "args {}\r\n",
        "\r\n",
        "muscle -in 969171403812395.18_18S.fasta\r\n",
        "muscle -in 969171403812395.18_28S.fasta\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file sequence_alignment.xml\n",
      "\n",
      "<tool id=\"sequence_alignment\" name=\"sequence alignment\" version=\"0.1\" hidden=\"false\">\n",
      "    <description>Define alignment method for each locus using a control\n",
      "    file and execute</description>\n",
      "    <command interpreter=\"python\">\n",
      "        sequence_alignment.py $pickle_input $controlfile $ReproPhylo_DB_file\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"pickle_input\" type=\"data\" label=\"ReproPhylo DB file (.pkl)\" >\n",
      "        </param>\n",
      "         <param name=\"controlfile\" type=\"data\" label=\"alignment methods file\" >\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"ReproPhylo_DB_file\" label=\"${tool.name} on ${on_string}: ReproPhylo DB file (.pkl)\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing sequence_alignment.xml\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Alignment trimming"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file trim_alignments.py\n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "pickle_output = sys.argv[2]\n",
      "\n",
      "pickle_handle = open(pickle_input, 'rb')\n",
      "\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "db.trim()\n",
      "\n",
      "import cloud.serialization.cloudpickle as pickle\n",
      "output = open(pickle_output,'wb')\n",
      "pickle.dump(db, output)\n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting trim_alignments.py\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file trim_alignments.xml\n",
      "\n",
      "<tool id=\"trim_alignments\" name=\"trim_alignments\" version=\"0.1\" hidden=\"false\">\n",
      "    <description>some description</description>\n",
      "    <command interpreter=\"python\">\n",
      "        trim_alignments.py $pickle_input $ReproPhylo_DB_file\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"pickle_input\" type=\"data\" label=\"ReproPhylo DB file (.pkl)\" >\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"ReproPhylo_DB_file\" label=\"${tool.name} on ${on_string}: ReproPhylo DB file (.pkl)\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing trim_alignments.xml\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tree reconstruction with raxml"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file example_raxml_file\n",
      "\n",
      "# Set\n",
      "# group of trimmed alignment names (either individual loci or concatenations)\n",
      "# usage:\n",
      "# set,name,aln1,aln2,...,alnn\n",
      "\n",
      "set,individual_loci,coi,18S,28S\n",
      "set,rRNA,18S,28S\n",
      "\n",
      "\n",
      "# Concatenation\n",
      "# Rules on which species to include\n",
      "# usage:\n",
      "# concatenation,name,loci(all or set),otu_meta,concat_must_have_all_of(set or locus),concat_must_have_one_of(set)1,concat_must_have_one_of(set)2...\n",
      "concatenation,combined,all,OTU_dict,coi,rRNA\n",
      "\n",
      "# Program\n",
      "# Set path to raxml\n",
      "# default: raxmlHPC\n",
      "# usage:\n",
      "# program,program_name,path/to/program/program_name\n",
      "\n",
      "program,raxmlHPC,raxmlHPC-PTHREADS-SSE3\n",
      "\n",
      "# Method\n",
      "# Assign raxml tree reconstruction method to alignments\n",
      "# usage:\n",
      "# method,method_name,preset,aln or aln set,model,matrix,numthreads,cline_arg1,value1,cline_arg2,value2,...,cline_argn,valuen\n",
      "\n",
      "method,ind_loci_method,fa,individual_loci,GAMMA,JTT,4,-#,4\n",
      "method,concats_method,fD_fb,combined,GAMMA,JTT,4,-N,4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting example_raxml_file\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file make_raxml_trees.py\n",
      "def parse_control_file(control_filename):\n",
      "    programs = {}\n",
      "    sets = {}\n",
      "    concatenations = {}\n",
      "    methods = {}\n",
      "    lines = []\n",
      "    # get rid of comments and blank lines\n",
      "    for line in open(control_filename,'r').readlines():\n",
      "        if not line[0] == '#' and not line[0] == '\\n':\n",
      "            lines.append(line.rstrip())\n",
      "    \n",
      "    available_commands = ['program','set','method','concatenation']\n",
      "    \n",
      "    for line in lines:\n",
      "            parts = line.split(',')\n",
      "            command = parts[0]\n",
      "            if command == 'program':\n",
      "                programs[parts[1]] = parts[2]\n",
      "            elif command == 'set':\n",
      "                sets[parts[1]] = parts[2:]\n",
      "            elif command == 'concatenation':\n",
      "                concatenations[parts[1]] = {'loci': parts[2],\n",
      "                                            'otu_meta': parts[3],\n",
      "                                            'concat_must_have_all_of': parts[4],\n",
      "                                            'concat_must_have_one_of': parts[5:]}\n",
      "            elif command == 'method':\n",
      "                cline_args = None\n",
      "                if len(parts) > 7:\n",
      "                    cline_args = parts[7:]\n",
      "                # method,method_name,preset,aln or aln set,model,matrix,numthreads,cline_arg1,value1,cline_arg2,value2,...,cline_argn,valuen\n",
      "                methods[parts[1]] = {'preset': parts[2],\n",
      "                                     'alns': parts[3],\n",
      "                                     'model': parts[4],\n",
      "                                     'matrix': parts[5],\n",
      "                                     'numthreads': parts[6],\n",
      "                                     'cline_args': cline_args}\n",
      "            else:\n",
      "                raise RuntimeError(command+' is an unknown command')\n",
      "                \n",
      "    return programs, sets, concatenations, methods\n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "control_file_name = sys.argv[2]\n",
      "pickle_output = sys.argv[3]\n",
      "\n",
      "pickle_handle = open(pickle_input, 'rb')\n",
      "\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "db.extract_by_locus()\n",
      "\n",
      "loci_names = db.records_by_locus.keys()\n",
      "\n",
      "\n",
      "programs, sets, concatenations, methods = parse_control_file(control_file_name)\n",
      "\n",
      "for concat_name in concatenations.keys():\n",
      "    concat_must_have_all_of = None\n",
      "    if concatenations[concat_name]['concat_must_have_all_of'] in loci_names:\n",
      "        concat_must_have_all_of = [concatenations[concat_name]['concat_must_have_all_of']]\n",
      "    elif concatenations[concat_name]['concat_must_have_all_of'] in sets.keys():\n",
      "        concat_must_have_all_of = sets[concatenations[concat_name]['concat_must_have_all_of']]\n",
      "    else:\n",
      "        raise RuntimeError('\\'concat_must_have_all_of\\' takes a locus or a set')\n",
      "        \n",
      "    concat_must_have_one_of = []\n",
      "    for i in concatenations[concat_name]['concat_must_have_one_of']:\n",
      "        concat_must_have_one_of.append(sets[i])\n",
      "    loci = []\n",
      "    if concatenations[concat_name]['loci'] == 'all':\n",
      "        loci = db.loci\n",
      "    elif concatenations[concat_name]['loci'] in sets.keys():\n",
      "        loci = filter(lambda locus: locus.name in sets[concatenations[concat_name]['loci']],\n",
      "                      db.loci)\n",
      "    \n",
      "    concat = Concatenation(name=concat_name,\n",
      "                           loci=loci,\n",
      "                           otu_meta=concatenations[concat_name]['otu_meta'],\n",
      "                           concat_must_have_all_of=concat_must_have_all_of,\n",
      "                           concat_must_have_one_of = concat_must_have_one_of)    \n",
      "    db.add_concatenation(concat)\n",
      "        \n",
      "db.make_concatenation_alignments()   \n",
      "aln_names = db.trimmed_alignments.keys()\n",
      "\n",
      "raxml_method_objects = []\n",
      "\n",
      "for method in methods.keys():\n",
      "    indicated_method_alns = methods[method]['alns']\n",
      "    alns_to_use = []\n",
      "    if indicated_method_alns == 'all':\n",
      "        alns_to_use = aln_names\n",
      "    elif indicated_method_alns in sets.keys():\n",
      "        alns_to_use = sets[indicated_method_alns]\n",
      "    elif indicated_method_alns in aln_names:\n",
      "        alns_to_use = [indicated_method_alns]\n",
      "    elif isinstance(indicated_method_alns,list):\n",
      "        raise IOError('alns for alignment method must be indicated by one aln name or one set name.'+\n",
      "                      ' List not accepted')\n",
      "    else:\n",
      "        raise IOError(indicated_method_alns + ' is not a recognized aln or set')\n",
      "   \n",
      "    cline_args = dict()\n",
      "    cline_args_dict = {}\n",
      "    if methods[method]['cline_args']:\n",
      "        if len(methods[method]['cline_args'])%2 > 0:\n",
      "            raise IOError('The number of cline args do no match the number of values in method '+method)\n",
      "        while methods[method]['cline_args']:\n",
      "            try:\n",
      "                cline_args_dict[methods[method]['cline_args'][0]] = int(methods[method]['cline_args'][1])\n",
      "            except:\n",
      "                try:\n",
      "                    cline_args_dict[methods[method]['cline_args'][0]] = float(methods[method]['cline_args'][1])\n",
      "                except:\n",
      "                    cline_args_dict[methods[method]['cline_args'][0]] = methods[method]['cline_args'][1]\n",
      "            methods[method]['cline_args'] = methods[method]['cline_args'][2:]\n",
      "    print\n",
      "    print\n",
      "    print 'building method ' + method\n",
      "    print 'preset ' + methods[method]['preset']\n",
      "    print 'method alns ' + str(alns_to_use)\n",
      "    print 'cmd ' + programs[programs.keys()[0]]\n",
      "    print 'model ' + methods[method]['model']\n",
      "    print 'matrix ' + methods[method]['matrix']\n",
      "    print 'numthreads ' + methods[method]['numthreads']\n",
      "    print 'args '+ str(cline_args_dict)\n",
      "    print\n",
      "    print\n",
      "    raxml_method_object = RaxmlTreeReconstructionMethod(db, \n",
      "                                              method_name=method,\n",
      "                                              program_name=programs.keys()[0],\n",
      "                                              cmd=programs[programs.keys()[0]],\n",
      "                                              preset = methods[method]['preset'],\n",
      "                                              alns = alns_to_use,\n",
      "                                              model = methods[method]['model'],\n",
      "                                              matrix = methods[method]['matrix'],\n",
      "                                              threads = methods[method]['numthreads'],\n",
      "                                              cline_args=cline_args_dict)\n",
      "\n",
      "    raxml_method_objects.append(raxml_method_object)\n",
      "\n",
      "db.tree(raxml_method_objects)\n",
      "\n",
      "import cloud.serialization.cloudpickle as pickle\n",
      "output = open(pickle_output,'wb')\n",
      "pickle.dump(db, output)\n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting make_raxml_trees.py\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python make_raxml_trees.py ReproPhylo_DB_file.pkl example_raxml_file database20.pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "building method concats_method\r\n",
        "preset fD_fb\r\n",
        "method alns ['combined']\r\n",
        "cmd raxmlHPC-PTHREADS-SSE3\r\n",
        "model GAMMA\r\n",
        "matrix JTT\r\n",
        "numthreads 4\r\n",
        "args {'-N': 4}\r\n",
        "\r\n",
        "\r\n",
        "raxmlHPC-PTHREADS-SSE3 -f D -m PROTGAMMAJTT -n 104081404946884.25_combined0 -q 104081404946884.25_combined_partfile -p 275 -s 104081404946884.25_combined.fasta -T 4 -N 4\r\n",
        "raxmlHPC-PTHREADS-SSE3 -f b -m PROTGAMMAJTT -n 104081404946884.25_combined1 -q 104081404946884.25_combined_partfile -p 586 -s 104081404946884.25_combined.fasta -t RAxML_bestTree.104081404946884.25_combined0 -T 4 -z RAxML_rellBootstrap.104081404946884.25_combined0\r\n",
        "\r\n",
        "\r\n",
        "building method ind_loci_method\r\n",
        "preset fa\r\n",
        "method alns ['coi', '18S', '28S']\r\n",
        "cmd raxmlHPC-PTHREADS-SSE3\r\n",
        "model GAMMA\r\n",
        "matrix JTT\r\n",
        "numthreads 4\r\n",
        "args {'-#': 4}\r\n",
        "\r\n",
        "\r\n",
        "raxmlHPC-PTHREADS-SSE3 -f a -m GTRGAMMA -n 209211404946884.26_coi0 -p 906 -s 209211404946884.26_coi.fasta -T 4 -x 703 -N 4\r\n",
        "raxmlHPC-PTHREADS-SSE3 -f a -m GTRGAMMA -n 209211404946884.26_18S0 -p 184 -s 209211404946884.26_18S.fasta -T 4 -x 112 -N 4\r\n",
        "raxmlHPC-PTHREADS-SSE3 -f a -m GTRGAMMA -n 209211404946884.26_28S0 -p 41 -s 209211404946884.26_28S.fasta -T 4 -x 388 -N 4\r\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "pickle_handle = open('database20.pkl', 'rb')\n",
      "\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "for tree in db.trees:\n",
      "    print db.trees[tree][1][:40]+'...'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(HM032747.2_f0:1.40557e-06[&&NHX:dist=1....\n",
        "((JX177971.1_f0:9.88549e-07[&&NHX:dist=9...\n",
        "(((JX177943.1_f0:0.00120484[&&NHX:dist=0...\n",
        "(((TAU_25622:1.06678e-06[&&NHX:source_sp...\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file make_raxml_trees.xml\n",
      "\n",
      "<tool id=\"make_raxml_trees\" name=\"make raxml trees\" version=\"0.1\" hidden=\"false\">\n",
      "    <description>Define raxml approach for each trimmed alignment using a control\n",
      "    file and execute</description>\n",
      "    <command interpreter=\"python\">\n",
      "        make_raxml_trees.py $pickle_input $controlfile $ReproPhylo_DB_file\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"pickle_input\" type=\"data\" label=\"ReproPhylo DB file (.pkl)\" >\n",
      "        </param>\n",
      "         <param name=\"controlfile\" type=\"data\" label=\"raxml methods file\" >\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"ReproPhylo_DB_file\" label=\"${tool.name} on ${on_string}: ReproPhylo DB file (.pkl)\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting make_raxml_trees.xml\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Annotate the trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file example_style_sheet_1\n",
      "\n",
      "# outgroup\n",
      "# usage: outgroup,qualifier, value\n",
      "outgroup,genus,Astrophorid\n",
      "\n",
      "# label_text\n",
      "# usage:\n",
      "# label_text,text_qualifiers\n",
      "label_text,feature_id,organism\n",
      "\n",
      "# label_colour (optional)\n",
      "# usage:\n",
      "# label_colour,qualifier,value1,colour1,...,valuen,colourn\n",
      "\n",
      "# clade_bg (optional)\n",
      "# usage:\n",
      "# clade_bg,qualifier,value1,colour1,...,valuen,colourn\n",
      "clade_bg,genus,Astrophorid,white,Cinachyrella,green,Paratetilla,yellowgreen,Amphitethya,olivedrab,Tetilla,skyblue,Cinachyra,firebrick,Acanthotetilla,silver,Fangophilina,crimson,Craniella,red\n",
      "\n",
      "# support\n",
      "# usage: support,colour1,start end1,colour2,start end2,...,colourn,start endn\n",
      "support,black,100 99, dimgray,99 75,silver,75 50\n",
      "\n",
      "# multifrucation\n",
      "# usage:multifrucation,value\n",
      "multifrucation,50\n",
      "\n",
      "# heat map\n",
      "# usage: heatmap,colour_scheme,qualifier1,qualifier2,...,qualifiern "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting example_style_sheet_1\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file example_style_sheet_2\n",
      "\n",
      "# outgroup\n",
      "# usage: outgroup,qualifier, value\n",
      "outgroup,genus,Astrophorid\n",
      "\n",
      "# label_text\n",
      "# usage:\n",
      "# label_text,text_qualifiers\n",
      "label_text,organism\n",
      "\n",
      "# label_colour (optional)\n",
      "# usage:\n",
      "# label_colour,qualifier,value1,colour1,...,valuen,colourn\n",
      "label_colour,genus,Astrophorid,black,Cinachyrella,black,Paratetilla,blue,Amphitethya,black,Tetilla,black,Cinachyra,black,Acanthotetilla,black,Fangophilina,black,Craniella,black,Craniella,black\n",
      "\n",
      "# clade_bg (optional)\n",
      "# usage:\n",
      "# clade_bg,qualifier,value1,colour1,...,valuen,colourn\n",
      "\n",
      "# support\n",
      "# usage: support,colour1,start end1,colour2,start end2,...,colourn,start endn\n",
      "support,black,100 99, dimgray,99 75,silver,75 50\n",
      "\n",
      "\n",
      "# multifrucation\n",
      "# usage:multifrucation,value\n",
      "multifrucation,50\n",
      "\n",
      "\n",
      "# heat map\n",
      "# usage: heatmap,colour_scheme,qualifier1,qualifier2,...,qualifiern \n",
      "heatmap,0,porocalices,cortex,calthrops\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting example_style_sheet_2\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file annotate_trees.py\n",
      "def parse_style_sheet(file_name):\n",
      "    lines = []\n",
      "    # get rid of comments and blank lines\n",
      "    for line in open(file_name,'r').readlines():\n",
      "        if not line[0] == '#' and not line[0] == '\\n':\n",
      "            lines.append(line.rstrip())\n",
      "    \n",
      "    available_commands = ['outgroup','label_text','label_colour','clade_bg','support','multifrucation','heatmap']\n",
      "    commands = []\n",
      "    \n",
      "    for line in lines:\n",
      "            parts = line.split(',')\n",
      "            if not parts[0] in available_commands:\n",
      "                raise RuntimeError(command+' is an unknown command')\n",
      "            else:\n",
      "                commands.append(parts)\n",
      "                \n",
      "    return commands\n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "style_sheet = sys.argv[2]\n",
      "pickle_output = sys.argv[3]\n",
      "fig_folder = sys.argv[4]\n",
      "\n",
      "pickle_handle = open(pickle_input, 'rb')\n",
      "\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "commands = parse_style_sheet(style_sheet)\n",
      "\n",
      "keyword_args = {}\n",
      "\n",
      "for command in commands:\n",
      "    if command[0] == 'outgroup':\n",
      "        keyword_args['root_meta'] = command[1]\n",
      "        keyword_args['root_value'] = command[2]\n",
      "    elif command[0] == 'label_text':\n",
      "        keyword_args['leaf_labels_txt_meta'] = command[1:]\n",
      "    elif command[0] == 'label_colour':\n",
      "        keyword_args['leaf_node_color_meta'] = command[1]\n",
      "        colors = {}\n",
      "        command_parts = command[2:]\n",
      "        while command_parts:\n",
      "            colors[command_parts[0]] = command_parts[1]\n",
      "            command_parts = command_parts[2:]\n",
      "        keyword_args['leaf_label_colors'] = colors\n",
      "    elif command[0] == 'clade_bg':\n",
      "        keyword_args['node_bg_meta'] = command[1]\n",
      "        colors = {}\n",
      "        command_parts = command[2:]\n",
      "        while command_parts:\n",
      "            colors[command_parts[0]] = command_parts[1]\n",
      "            command_parts = command_parts[2:]\n",
      "        keyword_args['node_bg_color'] = colors\n",
      "    elif command[0] == 'support':\n",
      "        colors = {}\n",
      "        command_parts = command[1:]\n",
      "        while command_parts:\n",
      "            values = command_parts[1].split(' ')\n",
      "            values = [int(i) for i in values]\n",
      "            colors[command_parts[0]] = values\n",
      "            command_parts = command_parts[2:]\n",
      "        keyword_args['node_support_dict'] = colors\n",
      "    elif command[0] == 'heatmap':\n",
      "        keyword_args['heat_map_colour_scheme'] = int(command[1])\n",
      "        keyword_args['heat_map_meta'] = command[2:]\n",
      "    elif command[0] == 'multifrucation':\n",
      "        keyword_args['multifruc'] = command[1]\n",
      "        \n",
      "db.annotate(fig_folder, **keyword_args)        \n",
      "\n",
      "import cloud.serialization.cloudpickle as pickle\n",
      "output = open(pickle_output,'wb')\n",
      "pickle.dump(db, output)\n",
      "output.close()    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting annotate_trees.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python annotate_trees.py ReproPhylo_DB_file_50.pkl example_style_sheet_2 database51.pkl .. > tree_fig_links.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file annotate_trees.xml\n",
      "\n",
      "<tool id=\"annotate_trees\" name=\"annotate trees\" version=\"0.1\" hidden=\"false\">\n",
      "    <description></description>\n",
      "    <command interpreter=\"python\">\n",
      "        annotate_trees.py $pickle_input $style_sheet $ReproPhylo_DB_file $fig_folder > $fig_links\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"pickle_input\" type=\"data\" label=\"ReproPhylo DB file (.pkl)\" >\n",
      "        </param>\n",
      "         <param name=\"style_sheet\" type=\"data\" label=\"Style sheet\" >\n",
      "        </param>\n",
      "         <param name=\"fig_folder\" type=\"text\" label=\"folder to keep the figs in\" >\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"ReproPhylo_DB_file\" label=\"${tool.name} on ${on_string}: ReproPhylo DB file (.pkl)\" />\n",
      "        <data name=\"fig_links\" format=\"html\" label=\"${tool.name} on ${on_string}: HTML text\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting annotate_trees.xml\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file print_report.py\n",
      "\n",
      "from reprophylo import *\n",
      "import sys, pickle\n",
      "\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "figures_folder = sys.argv[2]\n",
      "\n",
      "pickle_handle = open(pickle_input, 'rb')\n",
      "db = pickle.load(pickle_handle)\n",
      "\n",
      "for line in report_methods(db, figures_folder):\n",
      "    print line    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting print_report.py\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file print_report.xml\n",
      "\n",
      "<tool id=\"print_report\" name=\"print report\" version=\"0.1\" hidden=\"false\">\n",
      "    <description></description>\n",
      "    <command interpreter=\"python\">\n",
      "        print_report.py $pickle_input $fig_folder > $report\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"pickle_input\" type=\"data\" label=\"ReproPhylo DB file (.pkl)\" >\n",
      "        </param>\n",
      "         <param name=\"fig_folder\" type=\"text\" label=\"folder to keep the figs in\" >\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"report\" format=\"html\" label=\"${tool.name} on ${on_string}: HTML text\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting print_report.xml\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python print_report.py  database51.pkl > report.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Edit the loci file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file gb_to_loci.py \n",
      "import sys\n",
      "\n",
      "input_gb = sys.argv[1]\n",
      "output_loci_file = sys.argv[2]\n",
      "\n",
      "def make_loci_control_file_from_genbank(genbank_filename, control_filename):\n",
      "   from Bio import SeqIO\n",
      "   \n",
      "   # Open GenBank file\n",
      "   MelPCgenes = open(genbank_filename, 'rU')\n",
      "   \n",
      "   gene_dict = {} #set up a gene_dict dictionary\n",
      "   \n",
      "   # For each record\n",
      "   for record in SeqIO.parse(MelPCgenes, 'genbank') :\n",
      "   \n",
      "      # Grab the entire sequence\n",
      "      #seq = str(record.seq)  ## what is this actually used for? Nothing seems to happen on disabling it\n",
      "   \n",
      "      # Look at all features for this record\n",
      "      for feature in record.features:\n",
      "         \n",
      "         # If it's a CDS or rRNA...\n",
      "         if feature.type == 'CDS' or feature.type == 'rRNA':\n",
      "   \n",
      "            # If it contains some attribute called 'gene' save that\n",
      "            if 'gene' in feature.qualifiers:\n",
      "               geneName = feature.qualifiers['gene'][0]\n",
      "               geneName.replace(',',';')\n",
      "               if feature.type+','+geneName in gene_dict:\n",
      "                   gene_dict[feature.type+','+geneName]+=1\n",
      "               else:    \n",
      "                   gene_dict[feature.type+','+geneName]=1\n",
      "               #print(geneName)\n",
      "               \n",
      "            # Else if it contains some attribute called 'product' save that instead\n",
      "            elif 'product' in feature.qualifiers:\n",
      "               geneName = feature.qualifiers['product'][0]\n",
      "               geneName.replace(',',';')\n",
      "               if feature.type+','+geneName in gene_dict:\n",
      "                   gene_dict[feature.type+','+geneName]+=1\n",
      "               else:    \n",
      "                   gene_dict[feature.type+','+geneName]=1\n",
      "               #print(geneName)\n",
      "               \n",
      "            # Otherwise, quit.\n",
      "            else:\n",
      "               print 'ERROR when parsing feature: could not find either gene or product'\n",
      "               print feature.qualifiers\n",
      "               quit()\n",
      "   #print(gene_dict)\n",
      "       \n",
      "   #sorting happens via a list\n",
      "   \n",
      "   sorted = gene_dict.items()\n",
      "   sorted.sort(key = lambda i: i[0].lower())\n",
      "   \n",
      "   \n",
      "   \n",
      "   print('\\n' + \"There are \" + str(len(sorted)) + \" gene names (or gene product names) detected\")\n",
      "   print(\"---------------\")\n",
      "   print(\"Gene and count\")\n",
      "   print(\"---------------\")\n",
      "   \n",
      "   control_file_handle = open(control_filename, 'wt')\n",
      "   for key, value in sorted:\n",
      "           #print key, value\n",
      "           print(str(value) +\" instances of \" + key)\n",
      "           feature_type = key.split(',')[0]\n",
      "           alias = key.split(',')[1]\n",
      "           name = alias.replace(' ','_')\n",
      "           control_file_handle.write('dna,'+ feature_type + ',' + name + ',' + alias + '\\n')\n",
      "   control_file_handle.close()\n",
      "                    \n",
      "make_loci_control_file_from_genbank(input_gb, output_loci_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing gb_to_loci.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file gb_to_loci.xml\n",
      "\n",
      "<tool id=\"gb_to_loci\" name=\"gb to loci\" version=\"0.1\" hidden=\"false\">\n",
      "    <description></description>\n",
      "    <command interpreter=\"python\">\n",
      "        gb_to_loci.py $genbank $loci_file\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"genbank\" type=\"data\" label=\"genbank file\" >\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"loci_file\" type=\"data\" label=\"${tool.name} on ${on_string}: loci file\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing gb_to_loci.xml\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file synonimize_loci.py \n",
      "import sys\n",
      "\n",
      "edited_control_file = sys.argv[1]\n",
      "reformatted_control_file = sys.argv[2]\n",
      "\n",
      "def parse_manual_control_file(control_filename_input,control_filename_output):\n",
      "    control_file_lines = open(control_filename_input, 'r').readlines()\n",
      "    loci = {}\n",
      "    seen_syn_group = []\n",
      "    for line in [l.rstrip() for l in control_file_lines]:\n",
      "        char_type, feature_type, name, alias = line.split(',',3)\n",
      "        syn_group = None\n",
      "        if ',' in alias:\n",
      "            alias, syn_group = alias.split(',')\n",
      "\n",
      "        # checks\n",
      "        massage = \"\"\"This function accepts text files in which\n",
      "                     lines are of 4 or 5 comma separated values\n",
      "                     , which are char_type (dna or prot), feature_type,\n",
      "                     locus_name (no white spaces), alias (white spaces\n",
      "                     allowed), and potentialy a number linking the locus\n",
      "                     with other lines as a synonym\"\"\"\n",
      "        if syn_group and ',' in syn_group:\n",
      "            raise IOError(massage)\n",
      "        if syn_group and not syn_group.isdigit():\n",
      "            raise IOError(massage)\n",
      "        if not char_type in ('dna', 'prot'):\n",
      "            raise IOError(massage)\n",
      "        \n",
      "   \n",
      "        if syn_group and syn_group in seen_syn_group:\n",
      "            for key in loci.keys():\n",
      "                if loci[key]['syn_group'] == syn_group:\n",
      "                    loci[key]['aliases'].append(alias)\n",
      "\n",
      "        else:\n",
      "            loci[name] = {'char_type': char_type,\n",
      "                          'feature_type': feature_type,\n",
      "                          'aliases': [alias],\n",
      "                          'syn_group': syn_group}\n",
      "            seen_syn_group.append(syn_group)\n",
      "            \n",
      "\n",
      "    \n",
      "    output = open(control_filename_output, 'wt')\n",
      "    for name in loci.keys():\n",
      "        line = loci[name]['char_type']+','+loci[name]['feature_type']+','+name\n",
      "        for a in loci[name]['aliases']:\n",
      "            line += ','+a\n",
      "        line += '\\n'\n",
      "        output.write(line)\n",
      "    output.close()\n",
      "\n",
      "parse_manual_control_file(edited_control_file,reformatted_control_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing synonimize_loci.py\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file synonimize_loci.xml\n",
      "\n",
      "<tool id=\"synonimize_loci\" name=\"synonimize loci\" version=\"0.1\" hidden=\"false\">\n",
      "    <description></description>\n",
      "    <command interpreter=\"python\">\n",
      "        synonimize_loci.py $loci_file $synonimized_loci_file\n",
      "    </command>\n",
      "    <inputs>\n",
      "        <param name=\"loci_file\" type=\"data\" label=\"loci file\" >\n",
      "        </param>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <data name=\"synonimized_loci_file\" type=\"data\" label=\"${tool.name} on ${on_string}: synonimized loci file\" />\n",
      "    </outputs>\n",
      "</tool>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing synonimize_loci.xml\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Publish"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file publish.py\n",
      "\n",
      "from reprophylo import *\n",
      "import pickle, sys\n",
      "\n",
      "pickle_input = sys.argv[1]\n",
      "denovo_filename = [sys.argv[2]]\n",
      "char_type = sys.argv[3]\n",
      "picke_output = sys.argv[4]\n",
      "\n",
      "def publish(db, folder_name, figures_folder):\n",
      "    import os\n",
      "    folder = None\n",
      "    zip_file = None\n",
      "    if folder_name.endswith('.zip'):\n",
      "        zip_file = folder_name\n",
      "        folder = folder_name[:-4]\n",
      "    else:\n",
      "        folder = folder_name\n",
      "        zip_file = folder_name + '.zip'\n",
      "    if os.path.exists(folder) or os.path.exists(zip_file):\n",
      "        raise IOError(folder_name + ' already exists')\n",
      "    \n",
      "    os.makedirs(folder)\n",
      "    db.write(folder+'/tree_and_alns.nexml','nexml')\n",
      "    db.write(folder+'/sequences_and_metadata.gb','genbank')\n",
      "    report = open(folder+'/report.html','wt')\n",
      "    for line in report_methods(db, figures_folder):\n",
      "        report.write(line + '\\n')\n",
      "    report.close()\n",
      "\n",
      "    for tree in db.trees.keys():\n",
      "        if os.path.isfile(figures_folder+'/'+db.trees[tree][0].get_leaves()[0].tree_method_id+'.png'):\n",
      "            from shutil import copyfile\n",
      "            copyfile(figures_folder+'/'+db.trees[tree][0].get_leaves()[0].tree_method_id+'.png',\n",
      "                     folder+'/'+db.trees[tree][0].get_leaves()[0].tree_method_id+'.png')\n",
      "            \n",
      "         \n",
      "    \n",
      "    \n",
      "           \n",
      "    \n",
      "    import zipfile, shutil\n",
      "\n",
      "    zf = zipfile.ZipFile(zip_file, \"w\")\n",
      "    for dirname, subdirs, files in os.walk(folder):\n",
      "        zf.write(dirname)\n",
      "        for filename in files:\n",
      "            zf.write(os.path.join(dirname, filename))\n",
      "    zf.close()\n",
      "    shutil.rmtree(folder)\n",
      "publish(db, \"db_output\", '/home/amir/Dropbox/ReproPhylo')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}